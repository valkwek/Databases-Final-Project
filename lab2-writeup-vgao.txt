Describe any design decisions you made, including your choice of join and aggregate operator implementation. If you used something other than a nested-loops join, describe the tradeoffs of the algorithm you chose. If you implemented support for distinct in project_op.go, describe how you implemented it.
For join operator, we used a nested loop that iterated through the left operator once (outer loop) but iterated over the right iterator once for every tuple in the left iterator (inner loop). We implemented this by setting the right iterator to nil when initializing and also when we've finished iterating over all the tuples from the right iterator for one of the left iterator's tuples, at which point we want to reset the right iterator to run from its first tuple. 

For aggregate operator, we implemented the sum, max, min, and avg states and a design decision is the attributes of the state structs (i.e., SumAggState, AvgAggState, MinAggState, MaxAggState); we decided to include alias, expr, and some value(s) that help us compute the aggregated value when that state's Finalize() is called. For agg_op's extractGroupByKeyTuple, we just evaluated expression for each field in a.groupByFields and appended those expression values into the Fields attribute of the output Tuple; the output tuple's descriptor is also the output of the aggregator's Descriptor() method. For addTupleToGrpAggState, we iterated over the length of *grpAggState and if (*grpAggState)[i] is nil, we set (*grpAggState)[i] to be a copy of a.newAggState[i], which is a template. Outside the conditional checking if (*grpAggState)[i] is nil, we can call AddTuple on (*grpAggState)[i] because it's guaranteed to not be nil anymore. In getFinalizedTuplesIterator, the returned function gets the aggregation tuple that identifies a tuple from the groupByList via extractGroupByKeyTuple, get the aggregation states of that aggregation tuple by accessing the value in aggState map whose key is the tuple key of the aggregation tuple. If the aggregation states list isn't nil, we call Finalize() on each aggregation state and join the outputted tuple of Finalize() to the aggregation tuple. The first time the function returned by getFinalizedTuplesIterator is invoked, we process the last tuple in groupByList and the next time that function is invoked, we process the second to last tuple in groupByList. Essentially, we process the tuples in groupByList backwards.

For project operator, the Descriptor() outputs a TupleDesc that only contains field name and field type of the fields in p.selectFields. In the project iterator, we only evaluate expressions for fields in p.selectFields and add those expression values to the output tuple. To support distinct in project_up, we kept track of the distinct boolean and encounteredTuples (map with a tuple's key as a key and the tuple as the corresponding value) in the Project struct. In the project iterator, if distinct is true, we check if we've encountered an outputTuple; a tuple named outputTuple has been encountered if outputTuple.tupleKey() is already a key in the p.encounteredTuples maps. When distinct is true and a tuple has been encountered, we continue to the next tuple; otherwise, we append the tuple's key to p.encounteredTuples and return the tuple. If distinct is false, we always return the tuple and don't check if tuple's key is in p.encounteredTuples map.

For order by operator, we started with the OrderedBy(), Less(), Sort(), Len(), Swap(), lessFunc type, and multiSorter struct in Go's SortMultiKeys example. We used Tuple instead of Change type in that example. 
In the order by iterator, we first collected all the tuples from the o.child's iterator into an array of tuples. Then, we iterated over each of the fields we want to order tuples by in o.orderBy and checked whether each field is sorted in ascending or descending order. If the field is to be sorted in ascending order (ascending[i] is true where i is index of the field in o.orderBy), we define a less function that returns true when tuple 1's value for the field is less than tuple 2's value for the field. Otherwise, if the field is to be sorted in descending order, we define a less function that returns true if tuple 1's value for the field is greater than tuple 2's value for the field. For each field that we want to sort by, we append their less function into an array of less functions. Afterwards, we sort all the tuples collected in the array with the array of less functions (named sortFuncs) passed into the OrderedBy function and then call Sort() on the OrderedBy object with the array of tuples (named allTuples) as Sort()'s input: OrderedBy(sortFuncs...).Sort(allTuples). The last step is to initialize an index specifying which tuple in the sorted array of tuples we should return for the next invokation of the function returned by the order by iterator; if the index i is less than the length of the array of tuples, the function returned by the iterator would return the tuple at index i, nil; otherwise, that function returns nil, nil.

Discuss and justify any changes you made to the API.
We added attributes to the struct of some operators. 

In aggregate states, we added alias and expr attributes that were inputted into the functions initializing those states. For sum aggregation state, we also stored a sum attribute that we add to each time we insert a new tuple and return that value in Finalize(). For avg, we stored sumOfVals and numVals attributes; when inserting a new tuple, we add a DBValue to sumOfVals and increment numVals by 1. In AvgAggState's Finalize(), we return sumOfVals/numVals, which is guaranteed to not have division by zero errors because it was stated that we never call AvgAggState's Finalize() if we've never called AddTuple at least once. For min/max aggregate states, we store min/max attribute and update that value to be max(max attribute value, new tuple value) when inserting a tuple containing a new tuple value. When Finalize() is called for min/max aggregate state, we return min/max attribute of that state's struct.

For the insert/delete operators, we just stored the child operator and DBFile to insert/delete in the struct. 

To handle distinct project, we added distinct boolean and encounteredTuples (map with a tuple's key as a key and the tuple as the corresponding value) in the Project struct (explained above in Design Decisions section for Project operator).

For order by, we added ascending (array of booleans with true meaning a field should be sorted in ascending order, false meaning a field should be sorted in descending order) to OrderBy struct.

Describe any missing or incomplete elements of your code.
In buffer pool, we haven't implemented AbortTransaction, CommitTransaction, nor BeginTransaction nor dealt with locking.

Describe how long you spent on the lab, and whether there was anything you found particularly difficult or confusing.
8 hrs

Debugging in Go was challenging because it was hard to identify root cause of test cases failing. After adding many print statements in functions used by the test cases, we slowly narrowed down the cause of unexpected results. Figuring the meaning of/how to use pre-defined attributes of function parameter data types was a bit confusing because there weren't example values of some vague type names like Operator or Expr.